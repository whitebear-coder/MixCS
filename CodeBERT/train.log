06/15/2024 14:10:47 - WARNING - __main__ -   device: cuda, n_gpu: 4
06/15/2024 14:10:50 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/home/linzexu/codeNet_clf', output_dir='./saved_models', eval_data_file=None, test_data_file=None, model_name_or_path='microsoft/codebert-base', tokenizer_name='microsoft/codebert-base', block_size=256, do_train=True, do_eval=False, do_test=False, train_batch_size=8, eval_batch_size=16, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, warmup_steps=0, seed=123456, num_train_epochs=50, num_labels=10, n_gpu=4, device=device(type='cuda'))
/home/linzexu/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
06/15/2024 14:10:53 - INFO - __main__ -   ***** Running training *****
06/15/2024 14:10:53 - INFO - __main__ -     Num examples = 900
06/15/2024 14:10:53 - INFO - __main__ -     Num Epochs = 50
06/15/2024 14:10:53 - INFO - __main__ -     batch size = 8
06/15/2024 14:10:53 - INFO - __main__ -     Total optimization steps = 5650
  0%|          | 0/113 [00:00<?, ?it/s]/home/linzexu/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
epoch 0 loss 4.595:   0%|          | 0/113 [00:10<?, ?it/s]epoch 0 loss 4.595:   1%|          | 1/113 [00:10<18:57, 10.15s/it]epoch 0 loss 4.599:   1%|          | 1/113 [00:10<18:57, 10.15s/it]epoch 0 loss 4.599:   2%|▏         | 2/113 [00:10<08:15,  4.46s/it]epoch 0 loss 4.595:   2%|▏         | 2/113 [00:11<08:15,  4.46s/it]epoch 0 loss 4.595:   3%|▎         | 3/113 [00:11<04:50,  2.64s/it]epoch 0 loss 4.602:   3%|▎         | 3/113 [00:11<04:50,  2.64s/it]epoch 0 loss 4.602:   4%|▎         | 4/113 [00:11<03:14,  1.79s/it]epoch 0 loss 4.6:   4%|▎         | 4/113 [00:12<03:14,  1.79s/it]  epoch 0 loss 4.6:   4%|▍         | 5/113 [00:12<02:21,  1.31s/it]epoch 0 loss 4.597:   4%|▍         | 5/113 [00:12<02:21,  1.31s/it]epoch 0 loss 4.597:   5%|▌         | 6/113 [00:12<01:49,  1.02s/it]epoch 0 loss 4.601:   5%|▌         | 6/113 [00:12<01:49,  1.02s/it]epoch 0 loss 4.601:   6%|▌         | 7/113 [00:12<01:29,  1.19it/s]epoch 0 loss 4.599:   6%|▌         | 7/113 [00:13<01:29,  1.19it/s]epoch 0 loss 4.599:   7%|▋         | 8/113 [00:13<01:16,  1.37it/s]epoch 0 loss 4.602:   7%|▋         | 8/113 [00:13<01:16,  1.37it/s]epoch 0 loss 4.602:   8%|▊         | 9/113 [00:13<01:07,  1.54it/s]epoch 0 loss 4.602:   8%|▊         | 9/113 [00:14<01:07,  1.54it/s]epoch 0 loss 4.602:   9%|▉         | 10/113 [00:14<01:01,  1.67it/s]inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5710, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.7022, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5577, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5502, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6328, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5328, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6185, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6293, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5706, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5409, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6121, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6183, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6922, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5915, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5445, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6599, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5973, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5868, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5680, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6219, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5967, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5485, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6040, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5751, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6259, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5531, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6600, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6668, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5266, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5813, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6378, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6010, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
2: torch.Size([2, 256, 768])
4: torch.Size([2, 10])
3: torch.Size([2, 768])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6186, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6573, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5680, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6687, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
3: torch.Size([2, 768])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5857, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6224, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5745, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6283, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6690, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6963, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5962, device='cuda:0', grad_fn=<NegBackward0>)epoch 0 loss 4.605:   9%|▉         | 10/113 [00:14<01:01,  1.67it/s]epoch 0 loss 4.605:  10%|▉         | 11/113 [00:14<00:56,  1.80it/s]epoch 0 loss 4.607:  10%|▉         | 11/113 [00:15<00:56,  1.80it/s]epoch 0 loss 4.607:  11%|█         | 12/113 [00:15<00:53,  1.88it/s]epoch 0 loss 4.608:  11%|█         | 12/113 [00:15<00:53,  1.88it/s]epoch 0 loss 4.608:  12%|█▏        | 13/113 [00:15<00:51,  1.93it/s]epoch 0 loss 4.607:  12%|█▏        | 13/113 [00:16<00:51,  1.93it/s]epoch 0 loss 4.607:  12%|█▏        | 14/113 [00:16<00:50,  1.96it/s]epoch 0 loss 4.605:  12%|█▏        | 14/113 [00:16<00:50,  1.96it/s]epoch 0 loss 4.605:  13%|█▎        | 15/113 [00:16<00:48,  2.02it/s]epoch 0 loss 4.604:  13%|█▎        | 15/113 [00:17<00:48,  2.02it/s]epoch 0 loss 4.604:  14%|█▍        | 16/113 [00:17<00:47,  2.06it/s]epoch 0 loss 4.605:  14%|█▍        | 16/113 [00:17<00:47,  2.06it/s]epoch 0 loss 4.605:  15%|█▌        | 17/113 [00:17<00:46,  2.08it/s]epoch 0 loss 4.604:  15%|█▌        | 17/113 [00:18<00:46,  2.08it/s]epoch 0 loss 4.604:  16%|█▌        | 18/113 [00:18<00:45,  2.09it/s]epoch 0 loss 4.605:  16%|█▌        | 18/113 [00:18<00:45,  2.09it/s]epoch 0 loss 4.605:  17%|█▋        | 19/113 [00:18<00:45,  2.08it/s]epoch 0 loss 4.605:  17%|█▋        | 19/113 [00:19<00:45,  2.08it/s]epoch 0 loss 4.605:  18%|█▊        | 20/113 [00:19<00:44,  2.09it/s]epoch 0 loss 4.604:  18%|█▊        | 20/113 [00:19<00:44,  2.09it/s]epoch 0 loss 4.604:  19%|█▊        | 21/113 [00:19<00:43,  2.10it/s] torch.Size([2, 10])
tensor(4.5431, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6496, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6327, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6489, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5820, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
2: torch.Size([2, 256, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.7051, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5871, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5981, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5905, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5575, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6018, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6481, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5649, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6288, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5208, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5528, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6328, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
2: torch.Size([2, 256, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6152, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5850, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6010, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5694, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.7171, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6575, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5963, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5187, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
2: torch.Size([2, 256, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6242, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6246, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5514, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5548, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5992, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6487, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6285, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5650, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5908, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6604, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6436, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5630, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5499, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5207, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6642, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5398, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
3: torch.Size([2, 768])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
3: torch.Size([2, 768])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6633, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6310, device='cuda:1', grad_fn=<NegBackward0>)epoch 0 loss 4.603:  19%|█▊        | 21/113 [00:20<00:43,  2.10it/s]epoch 0 loss 4.603:  19%|█▉        | 22/113 [00:20<00:43,  2.11it/s]epoch 0 loss 4.602:  19%|█▉        | 22/113 [00:20<00:43,  2.11it/s]epoch 0 loss 4.602:  20%|██        | 23/113 [00:20<00:42,  2.10it/s]epoch 0 loss 4.603:  20%|██        | 23/113 [00:21<00:42,  2.10it/s]epoch 0 loss 4.603:  21%|██        | 24/113 [00:21<00:42,  2.09it/s]epoch 0 loss 4.602:  21%|██        | 24/113 [00:21<00:42,  2.09it/s]epoch 0 loss 4.602:  22%|██▏       | 25/113 [00:21<00:42,  2.09it/s]epoch 0 loss 4.601:  22%|██▏       | 25/113 [00:22<00:42,  2.09it/s]epoch 0 loss 4.601:  23%|██▎       | 26/113 [00:22<00:41,  2.09it/s]epoch 0 loss 4.599:  23%|██▎       | 26/113 [00:22<00:41,  2.09it/s]epoch 0 loss 4.599:  24%|██▍       | 27/113 [00:22<00:41,  2.09it/s]epoch 0 loss 4.6:  24%|██▍       | 27/113 [00:22<00:41,  2.09it/s]  epoch 0 loss 4.6:  25%|██▍       | 28/113 [00:23<00:40,  2.08it/s]epoch 0 loss 4.6:  25%|██▍       | 28/113 [00:23<00:40,  2.08it/s]epoch 0 loss 4.6:  26%|██▌       | 29/113 [00:23<00:40,  2.08it/s]epoch 0 loss 4.601:  26%|██▌       | 29/113 [00:23<00:40,  2.08it/s]epoch 0 loss 4.601:  27%|██▋       | 30/113 [00:23<00:39,  2.11it/s]epoch 0 loss 4.6:  27%|██▋       | 30/113 [00:24<00:39,  2.11it/s]  epoch 0 loss 4.6:  27%|██▋       | 31/113 [00:24<00:38,  2.11it/s]epoch 0 loss 4.601:  27%|██▋       | 31/113 [00:24<00:38,  2.11it/s]epoch 0 loss 4.601:  28%|██▊       | 32/113 [00:24<00:38,  2.11it/s] torch.Size([2, 10])
tensor(4.5184, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5207, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6198, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6012, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5683, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6095, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6988, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5520, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5863, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6232, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5749, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6098, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5383, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6076, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6019, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.4946, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5427, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6208, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5461, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6166, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5456, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5589, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6476, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5553, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5871, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6296, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
2: torch.Size([2, 256, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6340, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5684, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6011, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6247, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5789, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5855, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6607, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6958, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
2: torch.Size([2, 256, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5675, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5554, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6339, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5833, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
2: torch.Size([2, 256, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.6731, device='cuda:1', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6266, device='cuda:0', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.5865, device='cuda:2', grad_fn=<NegBackward0>) torch.Size([2, 10])
tensor(4.6237, device='cuda:3', grad_fn=<NegBackward0>) torch.Size([2, 10])
inputs:torch.Size([8, 256])
labels:torch.Size([8, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
3: torch.Size([2, 768])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
2: torch.Size([2, 256, 768])
2: torch.Size([2, 256, 768])
3: torch.Size([2, 768])
3: torch.Size([2, 768])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
4: torch.Size([2, 10])
5: torch.Size([2, 10])
tensor(4.5547, device='cuda:2', grad_fn=<NegBackward0>)epoch 0 loss 4.602:  28%|██▊       | 32/113 [00:25<00:38,  2.11it/s]epoch 0 loss 4.602:  29%|██▉       | 33/113 [00:25<00:38,  2.10it/s]epoch 0 loss 4.603:  29%|██▉       | 33/113 [00:25<00:38,  2.10it/s]epoch 0 loss 4.603:  30%|███       | 34/113 [00:25<00:37,  2.10it/s]epoch 0 loss 4.603:  30%|███       | 34/113 [00:26<00:37,  2.10it/s]epoch 0 loss 4.603:  31%|███       | 35/113 [00:26<00:37,  2.10it/s]epoch 0 loss 4.604:  31%|███       | 35/113 [00:26<00:37,  2.10it/s]epoch 0 loss 4.604:  32%|███▏      | 36/113 [00:26<00:36,  2.11it/s]epoch 0 loss 4.603:  32%|███▏      | 36/113 [00:27<00:36,  2.11it/s]epoch 0 loss 4.603:  33%|███▎      | 37/113 [00:27<00:36,  2.09it/s]epoch 0 loss 4.603:  33%|███▎      | 37/113 [00:27<00:36,  2.09it/s]epoch 0 loss 4.603:  34%|███▎      | 38/113 [00:27<00:35,  2.09it/s]epoch 0 loss 4.603:  34%|███▎      | 38/113 [00:28<00:35,  2.09it/s]epoch 0 loss 4.603:  35%|███▍      | 39/113 [00:28<00:35,  2.08it/s]epoch 0 loss 4.603:  35%|███▍      | 39/113 [00:28<00:35,  2.08it/s]epoch 0 loss 4.603:  35%|███▌      | 40/113 [00:28<00:35,  2.08it/s]epoch 0 loss 4.603:  35%|███▌      | 40/113 [00:29<00:35,  2.08it/s]epoch 0 loss 4.603:  36%|███▋      | 41/113 [00:29<00:34,  2.08it/s]epoch 0 loss 4.603:  36%|███▋      | 41/113 [00:29<00:34,  2.08it/s]epoch 0 loss 4.603:  37%|███▋      | 42/113 [00:29<00:33,  2.10it/s]epoch 0 loss 4.603:  37%|███▋      | 42/113 [00:30<00:33,  2.10it/s]